{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping basics for Selenium\n",
    "\n",
    "If you feel comfortable with scraping, you're free to skip this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Imports\n",
    "\n",
    "Import what you need to use Selenium, and start up a new Chrome to use for scraping. You might want to copy from the [Selenium snippets](http://jonathansoma.com/lede/foundations-2018/classes/selenium/selenium-snippets/) page.\n",
    "\n",
    "**You only need to do `driver = webdriver.Chrome(...)` once,** every time you do it you'll open a new Chrome instance. You'll only need to run it again if you close the window (or want another Chrome, for some reason)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "\n",
    "# response = requests.get(\"https://opensyllabus.org/results-list/titles?size=50&usState=AK\")\n",
    "# doc = BeautifulSoup(response.text)\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 5.1; hu-HU; rv:1.7.8) Gecko/20050511 Firefox/1.0.4'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 96.0.4664\n",
      "Get LATEST chromedriver version for 96.0.4664 google-chrome\n",
      "Driver [/Users/richardabbey/.wdm/drivers/chromedriver/mac64/96.0.4664.45/chromedriver] found in cache\n",
      "/var/folders/c4/ch89cvbs21d4cvs_ch64f2rh0000gn/T/ipykernel_6970/3124225037.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "#Launch a new Chrome, istalll a driver if possible\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Scraping by class\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/by-class.html, printing out the title, subhead, and byline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://jonathansoma.com/lede/static/by-class.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How to Scrape Things'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the class tag to identify the title\n",
    "driver.find_element(By.CLASS_NAME, \"title\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Supplemental Materials'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the class tag to identify the subhead\n",
    "driver.find_element(By.CLASS_NAME, \"subhead\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'By Jonathan Soma'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the class tag to identify the byline\n",
    "driver.find_element(By.CLASS_NAME, \"byline\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Scraping using tags\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/by-tag.html, printing out the title, subhead, and byline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/ch89cvbs21d4cvs_ch64f2rh0000gn/T/ipykernel_6970/256244417.py:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_tag_name(\"h1\").text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'How to Scrape Things'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element_by_tag_name(\"h1\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/ch89cvbs21d4cvs_ch64f2rh0000gn/T/ipykernel_6970/1463810.py:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_tag_name(\"h3\").text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Some Supplemental Materials'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element_by_tag_name(\"h3\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/ch89cvbs21d4cvs_ch64f2rh0000gn/T/ipykernel_6970/3389735881.py:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_tag_name(\"p\").text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'By Jonathan Soma'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element_by_tag_name(\"p\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Scraping using a single tag\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/by-list.html, printing out the title, subhead, and byline.\n",
    "\n",
    "> **This will be important for the next few:** if you scrape multiples, you have a list. Even though it's Seleninum, you can use things like `[0]`, `[1]`, `[-1]` etc just like you would for a normal list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Scrape Things\n",
      "Some Supplemental Materials\n",
      "By Jonathan Soma\n"
     ]
    }
   ],
   "source": [
    "# Looping through the table using a sinle tag, body\n",
    "table = driver.find_elements(By.TAG_NAME, \"body\")\n",
    "for row in table:\n",
    "    print(row.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Scraping a single table row\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/single-table-row.html, printing out the title, subhead, and byline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 96.0.4664\n",
      "Get LATEST chromedriver version for 96.0.4664 google-chrome\n",
      "Driver [/Users/richardabbey/.wdm/drivers/chromedriver/mac64/96.0.4664.45/chromedriver] found in cache\n",
      "/var/folders/c4/ch89cvbs21d4cvs_ch64f2rh0000gn/T/ipykernel_6970/603358049.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "#Launch a new Chrome, istalll a driver if possible\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get(\"http://jonathansoma.com/lede/static/single-table-row.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = driver.find_elements(By.TAG_NAME, \"tr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Scrape Things Some Supplemental Materials By Jonathan Soma\n"
     ]
    }
   ],
   "source": [
    "for row in table:\n",
    "    print(row.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Saving into a dictionary\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/single-table-row.html, saving the title, subhead, and byline into a single dictionary called `book`.\n",
    "\n",
    "> Don't use pandas for this one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': 'How to Scrape Things',\n",
       " 'Subhead': 'Some Supplemental Materials',\n",
       " 'Byline': 'By Jonathan Soma'}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This creates an empty dictionary\n",
    "#Loops through and empties the values into the empty disctionary\n",
    "#After that, the dictionary is appended to the master list, book\n",
    "\n",
    "all_books = doc.select(\"tbody tr td\")\n",
    "dataset = []\n",
    "\n",
    "for x in all_books:\n",
    "    book = {}\n",
    "    book ['Title'] = all_books[0].text\n",
    "    book ['Subhead'] = all_books[1].text\n",
    "    book ['Byline'] = all_books[2].text\n",
    "    dataset.append(book)\n",
    "    \n",
    "    \n",
    "book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_books = doc.select(\"tbody tr td\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = []\n",
    "\n",
    "# for x in all_books:\n",
    "#     book = {}\n",
    "#     book ['Title'] = all_books[0].text\n",
    "#     book ['Subhead'] = all_books[1].text\n",
    "#     book ['Byline'] = all_books[2].text\n",
    "#     dataset.append(book)\n",
    "    \n",
    "    \n",
    "# book\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Scraping multiple table rows\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/multiple-table-rows.html, printing out each title, subhead, and byline.\n",
    "\n",
    "> You won't use pandas for this one, either!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 96.0.4664\n",
      "Get LATEST chromedriver version for 96.0.4664 google-chrome\n",
      "Driver [/Users/richardabbey/.wdm/drivers/chromedriver/mac64/96.0.4664.45/chromedriver] found in cache\n",
      "/var/folders/c4/ch89cvbs21d4cvs_ch64f2rh0000gn/T/ipykernel_6970/3724066750.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "#Launch a new Chrome, istalll a driver if possible\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get(\"http://jonathansoma.com/lede/static/multiple-table-rows.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<html><head></head><body><table>\\n  <tbody><tr>\\n    <td>How to Scrape Things</td>\\n    <td>Some Supplemental Materials</td>\\n    <td>By Jonathan Soma</td>\\n  </tr>\\n  <tr>\\n    <td>How to Scrape Many Things</td>\\n    <td>But, Is It Even Possible?</td>\\n    <td>By Sonathan Joma</td>\\n  </tr>\\n  <tr>\\n    <td>The End of Scraping</td>\\n    <td>Let's All Use CSV Files</td>\\n    <td>By Amos Nathanos</td>\\n  </tr>\\n</tbody></table></body></html>\""
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = driver.find_elements(By.TAG_NAME, \"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____\n",
      "Title: How to Scrape Things\n",
      "Subhead: Some Supplemental Materials\n",
      "Byline: By Jonathan Soma\n",
      "_____\n",
      "Title: How to Scrape Many Things\n",
      "Subhead: But, Is It Even Possible?\n",
      "Byline: By Sonathan Joma\n",
      "_____\n",
      "Title: The End of Scraping\n",
      "Subhead: Let's All Use CSV Files\n",
      "Byline: By Amos Nathanos\n"
     ]
    }
   ],
   "source": [
    "#This loops through the table containing all the rows (tr's)\n",
    "#Prints the tags\n",
    "for row in table1:\n",
    "    book2 = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    print(\"_____\")\n",
    "    print(\"Title:\", book2[0].text)\n",
    "    print(\"Subhead:\", book2[1].text)\n",
    "    print(\"Byline:\", book2[2].text)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Scraping an actual table\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/the-actual-table.html, creating a list of dictionaries.\n",
    "\n",
    "> Don't use pandas here, either!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 96.0.4664\n",
      "Get LATEST chromedriver version for 96.0.4664 google-chrome\n",
      "Driver [/Users/richardabbey/.wdm/drivers/chromedriver/mac64/96.0.4664.45/chromedriver] found in cache\n",
      "/var/folders/c4/ch89cvbs21d4cvs_ch64f2rh0000gn/T/ipykernel_6970/3658142335.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "#Launch a new Chrome, istalll a driver if possible\n",
    "#Launch a new Chrome, istalll a driver if possible\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get(\"http://jonathansoma.com/lede/static/the-actual-table.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "booklist = driver.find_element(By.ID, 'booklist')\n",
    "new_book = booklist.find_elements(By.TAG_NAME, \"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Title': 'How to Scrape Things',\n",
       "  'Subhead': 'Some Supplemental Materials',\n",
       "  'Byline': 'By Jonathan Soma'},\n",
       " {'Title': 'How to Scrape Many Things',\n",
       "  'Subhead': 'But, Is It Even Possible?',\n",
       "  'Byline': 'By Sonathan Joma'},\n",
       " {'Title': 'The End of Scraping',\n",
       "  'Subhead': \"Let's All Use CSV Files\",\n",
       "  'Byline': 'By Amos Nathanos'}]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This creates an empty dictionary\n",
    "#Loops through and empties the values into the empty disctionary\n",
    "#After that, the dictionary is appended to the master list, book_data\n",
    "\n",
    "book_data =[]\n",
    "\n",
    "for row in new_book:\n",
    "    book_dict = {}\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    book_dict['Title'] = cells[0].text\n",
    "    book_dict['Subhead'] = cells[1].text\n",
    "    book_dict['Byline'] = cells[2].text\n",
    "    book_data.append(book_dict)\n",
    "\n",
    "book_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Scraping multiple table rows into a list of dictionaries\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/the-actual-table.html, creating a pandas DataFrame.\n",
    "\n",
    "> There are two ways to do this one! One uses just pandas, the other one uses the result from Part 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Title': 'How to Scrape Things',\n",
       "  'Subhead': 'Some Supplemental Materials',\n",
       "  'Byline': 'By Jonathan Soma'},\n",
       " {'Title': 'How to Scrape Many Things',\n",
       "  'Subhead': 'But, Is It Even Possible?',\n",
       "  'Byline': 'By Sonathan Joma'},\n",
       " {'Title': 'The End of Scraping',\n",
       "  'Subhead': \"Let's All Use CSV Files\",\n",
       "  'Byline': 'By Amos Nathanos'}]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This creates an empty dictionary\n",
    "#Loops through and empties the values into the empty disctionary\n",
    "#After that, the dictionary is appended to the master list, book_data\n",
    "#The resultant output is converted into a dataframe using df = pd.DataFrame(book_data)\n",
    "\n",
    "book_data =[]\n",
    "\n",
    "for row in new_book:\n",
    "    book_dict = {}\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    book_dict['Title'] = cells[0].text\n",
    "    book_dict['Subhead'] = cells[1].text\n",
    "    book_dict['Byline'] = cells[2].text\n",
    "    book_data.append(book_dict)\n",
    "\n",
    "book_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subhead</th>\n",
       "      <th>Byline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Scrape Things</td>\n",
       "      <td>Some Supplemental Materials</td>\n",
       "      <td>By Jonathan Soma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Scrape Many Things</td>\n",
       "      <td>But, Is It Even Possible?</td>\n",
       "      <td>By Sonathan Joma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The End of Scraping</td>\n",
       "      <td>Let's All Use CSV Files</td>\n",
       "      <td>By Amos Nathanos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title                      Subhead            Byline\n",
       "0       How to Scrape Things  Some Supplemental Materials  By Jonathan Soma\n",
       "1  How to Scrape Many Things    But, Is It Even Possible?  By Sonathan Joma\n",
       "2        The End of Scraping      Let's All Use CSV Files  By Amos Nathanos"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Scraping into a file\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/lede/static/the-actual-table.html and save it as `output.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This scrapes the data and creates a csv file using  df.to_csv(\"output.csv\", sep=',') with a comma separator\n",
    "\n",
    "book_data =[]\n",
    "\n",
    "for row in new_book:\n",
    "    book_dict = {}\n",
    "    cells = row.find_elements(By.TAG_NAME, 'td')\n",
    "    book_dict['Title'] = cells[0].text\n",
    "    book_dict['Subhead'] = cells[1].text\n",
    "    book_dict['Byline'] = cells[2].text\n",
    "    book_data.append(book_dict)\n",
    "\n",
    "df.to_csv(\"output.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Subhead</th>\n",
       "      <th>Byline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How to Scrape Things</td>\n",
       "      <td>Some Supplemental Materials</td>\n",
       "      <td>By Jonathan Soma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>How to Scrape Many Things</td>\n",
       "      <td>But, Is It Even Possible?</td>\n",
       "      <td>By Sonathan Joma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The End of Scraping</td>\n",
       "      <td>Let's All Use CSV Files</td>\n",
       "      <td>By Amos Nathanos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      Title                      Subhead  \\\n",
       "0           0       How to Scrape Things  Some Supplemental Materials   \n",
       "1           1  How to Scrape Many Things    But, Is It Even Possible?   \n",
       "2           2        The End of Scraping      Let's All Use CSV Files   \n",
       "\n",
       "             Byline  \n",
       "0  By Jonathan Soma  \n",
       "1  By Sonathan Joma  \n",
       "2  By Amos Nathanos  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
